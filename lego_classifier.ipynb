{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LEGOCLASSIFIER-V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcnGu3IJpuF7"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVM3kZRCQ34A",
        "outputId": "adce9146-717e-4b11-93dc-435dc4df7f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHf3y6VUz1BM"
      },
      "source": [
        "HEIGHT = 300\n",
        "WIDTH = 300\n",
        "\n",
        "# base_model = ResNet50(weights='imagenet', \n",
        "#                       include_top=False, \n",
        "#                       input_shape=(HEIGHT, WIDTH, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "can2JPeWz2u0"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/My Drive/LegoImages2.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/Lego\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgk7U3P1z9tQ",
        "outputId": "09964fc5-f3d8-4e82-ddce-0c5f7f4b60c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_DIR = \"/content/Lego/LegoImages2\"\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 194400 images belonging to 600 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaHBvrcZWjO"
      },
      "source": [
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "FC_LAYERS = [1024, 1024]\n",
        "dropout = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=600)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYjudaW71GVa",
        "outputId": "8ad2fb91-d4f8-4a9a-d560-644fd7365063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "num_train_images = 194400\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath=\"/content/drive/My Drive/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max',period=5)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 486s 320ms/step - loss: 6.5057 - accuracy: 0.0020\n",
            "Epoch 2/10\n",
            "1518/1518 [==============================] - 460s 303ms/step - loss: 6.3933 - accuracy: 0.0030\n",
            "Epoch 3/10\n",
            "1518/1518 [==============================] - 465s 306ms/step - loss: 6.3648 - accuracy: 0.0036\n",
            "Epoch 4/10\n",
            "1518/1518 [==============================] - 461s 304ms/step - loss: 6.3018 - accuracy: 0.0051\n",
            "Epoch 5/10\n",
            "1518/1518 [==============================] - 464s 306ms/step - loss: 6.2481 - accuracy: 0.0054\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/ResNet50_model_weights.h5\n",
            "Epoch 6/10\n",
            "1518/1518 [==============================] - 484s 319ms/step - loss: 6.1553 - accuracy: 0.0093\n",
            "Epoch 7/10\n",
            "1518/1518 [==============================] - 475s 313ms/step - loss: 6.0672 - accuracy: 0.0123\n",
            "Epoch 8/10\n",
            "1518/1518 [==============================] - 482s 318ms/step - loss: 5.9653 - accuracy: 0.0152\n",
            "Epoch 9/10\n",
            "1518/1518 [==============================] - 475s 313ms/step - loss: 5.8565 - accuracy: 0.0201\n",
            "Epoch 10/10\n",
            "1518/1518 [==============================] - 475s 313ms/step - loss: 5.7041 - accuracy: 0.0280\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/ResNet50_model_weights.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQ8GOM3r2TK",
        "outputId": "c38909f6-82ac-41c1-96d9-04d1031e5cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(4):\n",
        "  NUM_EPOCHS = 10\n",
        "  BATCH_SIZE = 128\n",
        "  num_train_images = 194400\n",
        "\n",
        "  adam = Adam(lr=0.00001)\n",
        "  finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  filepath=\"/content/drive/My Drive/\" + \"ResNet50-\" +str(i)+\"_model_weights.h5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max',period=5)\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 738s 486ms/step - loss: 6.5119 - accuracy: 0.0018\n",
            "Epoch 2/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 6.4020 - accuracy: 0.0020\n",
            "Epoch 3/10\n",
            "1518/1518 [==============================] - 712s 469ms/step - loss: 6.3589 - accuracy: 0.0037\n",
            "Epoch 4/10\n",
            "1518/1518 [==============================] - 710s 468ms/step - loss: 6.3121 - accuracy: 0.0058\n",
            "Epoch 5/10\n",
            "1518/1518 [==============================] - 710s 468ms/step - loss: 6.2560 - accuracy: 0.0068\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/ResNet50-0_model_weights.h5\n",
            "Epoch 6/10\n",
            "1518/1518 [==============================] - 714s 471ms/step - loss: 6.1838 - accuracy: 0.0082\n",
            "Epoch 7/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 6.1000 - accuracy: 0.0107\n",
            "Epoch 8/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 6.0209 - accuracy: 0.0149\n",
            "Epoch 9/10\n",
            "1518/1518 [==============================] - 712s 469ms/step - loss: 5.9601 - accuracy: 0.0161\n",
            "Epoch 10/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 5.9164 - accuracy: 0.0177\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/ResNet50-0_model_weights.h5\n",
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 729s 480ms/step - loss: 5.8121 - accuracy: 0.0207\n",
            "Epoch 2/10\n",
            "1518/1518 [==============================] - 715s 471ms/step - loss: 5.7404 - accuracy: 0.0284\n",
            "Epoch 3/10\n",
            "1518/1518 [==============================] - 715s 471ms/step - loss: 5.6553 - accuracy: 0.0307\n",
            "Epoch 4/10\n",
            "1518/1518 [==============================] - 715s 471ms/step - loss: 5.5804 - accuracy: 0.0346\n",
            "Epoch 5/10\n",
            "1518/1518 [==============================] - 718s 473ms/step - loss: 5.5400 - accuracy: 0.0352\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/ResNet50-1_model_weights.h5\n",
            "Epoch 6/10\n",
            "1518/1518 [==============================] - 725s 478ms/step - loss: 5.4467 - accuracy: 0.0469\n",
            "Epoch 7/10\n",
            "1518/1518 [==============================] - 722s 475ms/step - loss: 5.3579 - accuracy: 0.0529\n",
            "Epoch 8/10\n",
            "1518/1518 [==============================] - 722s 475ms/step - loss: 5.3147 - accuracy: 0.0522\n",
            "Epoch 9/10\n",
            "1518/1518 [==============================] - 723s 476ms/step - loss: 5.2441 - accuracy: 0.0593\n",
            "Epoch 10/10\n",
            "1518/1518 [==============================] - 725s 478ms/step - loss: 5.1334 - accuracy: 0.0738\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/ResNet50-1_model_weights.h5\n",
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 751s 495ms/step - loss: 5.0637 - accuracy: 0.0776\n",
            "Epoch 2/10\n",
            "1518/1518 [==============================] - 725s 478ms/step - loss: 5.0113 - accuracy: 0.0829\n",
            "Epoch 3/10\n",
            "1518/1518 [==============================] - 714s 470ms/step - loss: 4.9498 - accuracy: 0.0898\n",
            "Epoch 4/10\n",
            "1518/1518 [==============================] - 714s 470ms/step - loss: 4.8741 - accuracy: 0.0979\n",
            "Epoch 5/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 4.8156 - accuracy: 0.1063\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/ResNet50-2_model_weights.h5\n",
            "Epoch 6/10\n",
            "1518/1518 [==============================] - 719s 474ms/step - loss: 4.7697 - accuracy: 0.1123\n",
            "Epoch 7/10\n",
            "1518/1518 [==============================] - 718s 473ms/step - loss: 4.6740 - accuracy: 0.1252\n",
            "Epoch 8/10\n",
            "1518/1518 [==============================] - 719s 474ms/step - loss: 4.6092 - accuracy: 0.1322\n",
            "Epoch 9/10\n",
            "1518/1518 [==============================] - 721s 475ms/step - loss: 4.5220 - accuracy: 0.1437\n",
            "Epoch 10/10\n",
            "1518/1518 [==============================] - 720s 475ms/step - loss: 4.4782 - accuracy: 0.1492\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/ResNet50-2_model_weights.h5\n",
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 735s 484ms/step - loss: 4.4002 - accuracy: 0.1618\n",
            "Epoch 2/10\n",
            "1518/1518 [==============================] - 718s 473ms/step - loss: 4.3871 - accuracy: 0.1648\n",
            "Epoch 3/10\n",
            "1518/1518 [==============================] - 719s 474ms/step - loss: 4.3075 - accuracy: 0.1748\n",
            "Epoch 4/10\n",
            "1518/1518 [==============================] - 720s 474ms/step - loss: 4.2528 - accuracy: 0.1835\n",
            "Epoch 5/10\n",
            "1518/1518 [==============================] - 723s 476ms/step - loss: 4.2240 - accuracy: 0.1858\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/ResNet50-3_model_weights.h5\n",
            "Epoch 6/10\n",
            "1518/1518 [==============================] - 724s 477ms/step - loss: 4.1537 - accuracy: 0.1919\n",
            "Epoch 7/10\n",
            "1518/1518 [==============================] - 725s 478ms/step - loss: 4.0871 - accuracy: 0.2007\n",
            "Epoch 8/10\n",
            "1518/1518 [==============================] - 727s 479ms/step - loss: 4.0125 - accuracy: 0.2142\n",
            "Epoch 9/10\n",
            " 198/1518 [==>...........................] - ETA: 10:26 - loss: 3.9876 - accuracy: 0.2323Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Sn9gmKNZlN",
        "outputId": "3bc215e2-9234-473c-d597-83989aead1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/\" + \"ResNet50NEWEST\" + \"_model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max',period=1)\n",
        "callbacks_list = [checkpoint]\n",
        "history = finetune_model.fit_generator(train_generator, epochs=1, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1518/1518 [==============================] - 502s 331ms/step - loss: 4.0134 - accuracy: 0.1531\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/ResNet50NEWEST_model_weights.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNAuXGU8ytJC",
        "outputId": "17f65884-e0c4-4c13-cda4-d10293b15f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(4,9):\n",
        "  NUM_EPOCHS = 10\n",
        "  BATCH_SIZE = 128\n",
        "  num_train_images = 194400\n",
        "\n",
        "  adam = Adam(lr=0.00001)\n",
        "  finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  filepath=\"/content/drive/My Drive/\" + \"ResNet50-\" +str(i)+\"_model_weights.h5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max',period=5)\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 732s 482ms/step - loss: 3.8551 - accuracy: 0.2411\n",
            "Epoch 2/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 3.8411 - accuracy: 0.2402\n",
            "Epoch 3/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 3.7907 - accuracy: 0.2512\n",
            "Epoch 4/10\n",
            "1518/1518 [==============================] - 714s 470ms/step - loss: 3.7526 - accuracy: 0.2572\n",
            "Epoch 5/10\n",
            "1518/1518 [==============================] - 714s 470ms/step - loss: 3.7220 - accuracy: 0.2582\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/ResNet50-4_model_weights.h5\n",
            "Epoch 6/10\n",
            "1518/1518 [==============================] - 716s 472ms/step - loss: 3.6247 - accuracy: 0.2684\n",
            "Epoch 7/10\n",
            "1518/1518 [==============================] - 713s 470ms/step - loss: 3.6072 - accuracy: 0.2754\n",
            "Epoch 8/10\n",
            "1277/1518 [========================>.....] - ETA: 1:53 - loss: 3.5682 - accuracy: 0.2805"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v7-0031KgXs",
        "outputId": "c676b760-3e15-42ff-90bc-68e08b2b971a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(4,9):\n",
        "  NUM_EPOCHS = 10\n",
        "  BATCH_SIZE = 128\n",
        "  num_train_images = 194400\n",
        "\n",
        "  adam = Adam(lr=0.00001)\n",
        "  finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  filepath=\"/content/drive/My Drive/\" + \"ResNet50-\" +str(i)+\"_model_weights.h5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max',period=5)\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ef02cdd4eba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mfinetune_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ResNet50-\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_model_weights.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'finetune_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OebpcQpIZIcf",
        "outputId": "093f9e26-4782-4ebd-b70b-19a6a2c4a93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(finetune_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.engine.training.Model"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSkOGxUcZa3u",
        "outputId": "556909fd-7ce0-44c3-8d07-2deff9e2bb0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.training.Model"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1hktz9AXbSW"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/ResNet50-19_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY1RW2_cjG1N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANnmS5CXbF-"
      },
      "source": [
        "top_values_index = sorted(range(len(class_prob)), key=lambda i: class_prob[i])[-5:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C5jBNJDoN_5",
        "outputId": "c595fec1-d2ba-4e88-c360-fb8d4af91dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "top_values_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 4, 6, 3, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXQKAFvvURkw",
        "outputId": "eb4fb7c9-0392-4393-cadd-96ef9cc3e751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TEST_DIR = \"/content/drive/My Drive/TESTTT\"\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "test_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      # rotation_range=90,\n",
        "      # horizontal_flip=True,\n",
        "      # vertical_flip=True\n",
        "    )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(TEST_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KNchX71Vgau"
      },
      "source": [
        "test_generator.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGw27gaPVgWM",
        "outputId": "f0616a78-d1c9-443a-cc8a-79184dc0b3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred=model.predict_generator(test_generator,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 35ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibk8l0QDzLSi"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI9KACxOzLRl"
      },
      "source": [
        "!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png\n",
        "import cv2\n",
        "img = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ5rAvhTbXtp"
      },
      "source": [
        "import numpy as np\n",
        "p1=np.array(pred[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7rMKjyDsiOj",
        "outputId": "30cb82c4-1a6f-48bb-d376-868a260d48ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p1[192]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.6358725e-25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JbqNtb_oddR",
        "outputId": "2d344b8d-794d-42d0-f212-3a54bce600a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "top_values_index = sorted(range(len(p1)), key=lambda i: p1[i])[-10:]\n",
        "top_values_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[392, 125, 35, 6, 126, 450, 405, 548, 212, 446]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0MaliLpojui",
        "outputId": "384bd586-1fce-43fc-bc53-a079f2415b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-a7c6af6e3dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9_c5a5ChpR-",
        "outputId": "a2991fd3-0ee5-480f-a14c-752ad0378dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "top_values_index = sorted(range(len(p1)), key=lambda i: p1[i])[-10:]\n",
        "top_values_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[198, 502, 559, 472, 468, 567, 405, 126, 446, 450]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29CnCa5mcDWO"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uJ60Dxxb2Ft"
      },
      "source": [
        "output = [dI for dI in os.listdir('/content/Lego/LegoImages2') if\n",
        "          os.path.isdir(os.path.join('/content/Lego/LegoImages2', dI))]\n",
        "output.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSRu3M59cFDm",
        "outputId": "56622cd4-c997-46e2-94a7-175563615eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output[380]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'43713'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSQ_qW2lbrLh",
        "outputId": "b9fc9e2a-ec82-47b3-bbea-972afb93a2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(p1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLLRElsRb78f",
        "outputId": "6130775d-184d-44b3-a79d-8b885fa7d0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "for i in range(20,60):\n",
        "  NUM_EPOCHS = 10\n",
        "  BATCH_SIZE = 128\n",
        "  num_train_images = 194400\n",
        "\n",
        "  adam = Adam(lr=0.00001)\n",
        "  filepath=\"/content/drive/My Drive/\" + \"ResNet50-\" +str(i)+\"_model_weights.h5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max',period=5,save_weights_only=False)\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True,callbacks=callbacks_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1518/1518 [==============================] - 421s 277ms/step - loss: 0.7737 - accuracy: 0.7592\n",
            "Epoch 2/10\n",
            "  71/1518 [>.............................] - ETA: 6:39 - loss: 0.7109 - accuracy: 0.7782"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcVA5xMzKsBN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}